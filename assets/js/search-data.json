{
  
    
        "post0": {
            "title": "Linear Algebra by Prof. Gilbert Strang—Notes from a Programmer",
            "content": "This notebook exhibits the concepts taught through this course using numpy, scipy, and matplotlib: . Gilbert Strang. 18.06 Linear Algebra. Spring 2010. Massachusetts Institute of Technology: MIT OpenCourseWare, https://ocw.mit.edu. License: Creative Commons BY-NC-SA. Direct Link | . Contents . Create my chosen array | Basic operations Transpose Matrix (2D array) | Vector (1D array) | Vector (2D array) | . | Inverse | . | Decompositions LU | QR | Diagonalization (Eigendecomposition) | . | Subspaces Column Space C(A) Manually QR Orthonormal basis | Independent columns | . | LU (Independent columns) | . | . | Null Space N(A) | Row Space C(At) | Left Null Space N(At) | . | Rank-one matrix | Least Squares Manually | Fitting a line/parabola | . | Properties of the determinant $|AB| = |A||B|$ | $|A^{-1}| = frac{1}{|A|}$ | $|A^2|=|A|^2$ | $|2A|=2^n |A|$ | $|A^T|=|A|$ | $|U|=|A|$ | $|Q|=1$ | . | Eigenvalues and eigenvectors Product of eigenvalues | Sum of eigenvalues | Adding to the diagonal adds to lambdas | Attributes of a diagonal matrix | Rotation matrix often has complex lambdas | . | Diagonalizability Algebraic &amp; Geometric Multiplicity | Defective matrix | Diagonalizable matrix Normal Hermitian | Unitary | . | . | . | Matrix Power $A^{k}$ A diagonal matrix | Any matrix | . | Matrix Exponential $e^{At}$ A diagonal matrix | Any matrix | . | Systems of difference equations Discrete $u_{k}=A^{k}u_{0}$ e.g. Fibonacci | Convergence Stability | Steady State | Blow Up | . | Analyze Graph | . | . | Continuous $u(t)=e^{At}u(0)$ e.g. A 2×2 system of diff eqs | e.g. A 2nd order diff eq | Convergence Stability | Steady State | Blow Up | . | Analyze Graph | . | . | . | Markov matrix All entries are 0 or positive | All columns add to 1 | $ exists i: lambda_{i} = 1$ | $ forall j ne i , | lambda_{j}| leq 1$ | It converges to a positive steady state | $A^{k}$ is still Markov | . | Expansion with a basis With A | With Q (orthonormal basis) | With S (eigenvectors) | . | Complex Vectors and Matrices Hermitian matrix | Unitary matrix | . | Positive Definite Matrices | Requirements . import numpy as np, numpy.linalg as npLA from numpy.linalg import matrix_power from numpy.testing import assert_allclose, assert_array_less, assert_ from scipy import linalg as LA from scipy.linalg import inv, det, expm import matplotlib.pyplot as plt . from utility import * %load_ext autoreload %autoreload 1 %aimport utility . # formatter={&#39;float_kind&#39;:&#39;{:_.1f}&#39;.format} np.set_printoptions(precision=1, suppress=True) . &amp;#x21e7; . Create my chosen array . def create_a_square_invertible_array(): &quot;&quot;&quot;Invertible (M == N)&quot;&quot;&quot; return np.array([[1, 2, 1], [3, 8, 1], [0, 4, 1]]) def create_a_square_singular_array(): &quot;&quot;&quot;Singular M == N&quot;&quot;&quot; return np.array([[1, 1, 4], [2, 2, 5], [3, 3, 6]]) def create_a_Hermitian_array(): &quot;&quot;&quot;Hermitian (M == N)&quot;&quot;&quot; return np.array([[1 , 2j, 1+1j], [ -2j, 8 , 4-3j], [1-1j, 4+3j, -3 ]]) def create_a_unitary_array(): &quot;&quot;&quot;Unitary (M == N)&quot;&quot;&quot; return np.array([[.5+.5j, .5-.5j], [.5-.5j, .5+.5j]]) def create_a_Markov_matrix(): &quot;&quot;&quot;Markov (M == N)&quot;&quot;&quot; return np.array([[.1, .01, .3], [.2, .99, .3], [.7, 0 , .4]]) def create_a_Jordan_array(): &quot;&quot;&quot;Jordan (M == N)&quot;&quot;&quot; return np.array([[3, 1, 0], [0, 3, 1], [0, 0, 3]]) def create_a_tall_array(): &quot;&quot;&quot;Tall (M &gt; N)&quot;&quot;&quot; return np.array([[1, 1], [2, 2], [3, 4], [4, 1]]) def create_a_fat_array(): &quot;&quot;&quot;Fat (M &lt; N)&quot;&quot;&quot; return np.array([[1, 2, 3, 4], [1, 2, 4, 1]]) def create_a_3d_array_leading_to_stability_in_discrete_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a discrete differential equation that leads to stability&quot;&quot;&quot; return np.array([[ 0.1, 0 , 0.5], [ 0 , 0.1, 0 ], [-0.5, 0 , -0.1]]) def create_a_3d_array_leading_to_steady_state_in_discrete_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a discrete differential equation that leads to steady state&quot;&quot;&quot; return np.array([[ 0.2, 0 , 1 ], [ 0 , 0.2, 0 ], [-1 , 0 , -0.1]]) def create_a_3d_array_blowing_up_in_discrete_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a discrete differential equation that blows up&quot;&quot;&quot; return np.array([[ 1, 1 , 1 ], [-1, 0.5, 0 ], [-1, 0 , -0.5]]) def create_a_3d_array_leading_to_stability_in_continuous_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a continuous differential equation that leads to stability&quot;&quot;&quot; return np.array([[-0.8, 1 , 1 ], [-1 ,-0.6, 1 ], [-1 , 1 , -0.7]]) def create_a_3d_array_leading_to_steady_state_in_continuous_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a continuous differential equation that leads to steady state&quot;&quot;&quot; return np.array([[-0.6, 1 , 1 ], [-1 ,-0.5, 1 ], [-1 , 1 , -0.6]]) def create_a_3d_array_blowing_up_in_continuous_diff_eq(): &quot;&quot;&quot;A 3 by 3 array for a continuous differential equation that blows up&quot;&quot;&quot; return np.array([[ 1, 1 , 1 ], [-1, 0.5, 0 ], [-1, 0 , -0.5]]) def create_a_2d_array_leading_to_stability_in_discrete_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a discrete differential equation that leads to stability&quot;&quot;&quot; return np.array([[ 0.1, 0.5], [-0.5, 0.2]]) def create_a_2d_array_leading_to_steady_state_in_discrete_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a discrete differential equation that leads to steady state&quot;&quot;&quot; return np.array([[ 0.8, 0.5], [-0.5, 0.9]]) def create_a_2d_array_blowing_up_in_discrete_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a discrete differential equation that blows up&quot;&quot;&quot; return np.array([[ 0.5, 1 ], [-1 , 0.8]]) def create_a_2d_array_leading_to_stability_in_continuous_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a continuous differential equation that leads to stability&quot;&quot;&quot; return np.array([[-0.3, 1 ], [-1 , -0.1]]) def create_a_2d_array_leading_to_steady_state_in_continuous_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a continuous differential equation that leads to steady state&quot;&quot;&quot; return np.array([[ 0, 1 ], [-1, -0.1]]) def create_a_2d_array_blowing_up_in_continuous_diff_eq(): &quot;&quot;&quot;A 2 by 2 array for a continuous differential equation that blows up&quot;&quot;&quot; return np.array([[ 0.3, 1 ], [-1 , 0.1]]) def create_my_array(): &quot;&quot;&quot;The array I wish to see its attributes throughout the majority of cells. Feel free to change it!&quot;&quot;&quot; return create_a_square_invertible_array() A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . &amp;#x21e7; . Basic operations . Transpose . Matrix (2D array) . A = np.arange(1, 5).reshape((2, 2)) print(A) . [[1 2] [3 4]] . print(A.T) . [[1 3] [2 4]] . Vector (1D array) . b = np.arange(3) print(b) . [0 1 2] . print(b.T) . [0 1 2] . A 1D array is the same as its transpose. . 1D arrays will automatically transform to (perhaps transpose) 2D ones when they are on either side of @ functions. . Vector (2D array) . x = np.arange(3).reshape((1, 3)) print(x) . [[0 1 2]] . print(x.T) . [[0] [1] [2]] . Inverse . A = np.array([[1, 2], [3, 1]]) Ai = LA.inv(A) print(Ai) . [[-0.2 0.4] [ 0.6 -0.2]] . &amp;#x21e7; . Decompositions . LU . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . P, L, U = LA.lu(A) print(&#39;P&#39;, P, &#39;&#39;, &#39;L&#39;, L, &#39;&#39;, &#39;U&#39;, U, sep=&#39; n&#39;) . P [[0. 0. 1.] [1. 0. 0.] [0. 1. 0.]] L [[ 1. 0. 0. ] [ 0. 1. 0. ] [ 0.3 -0.2 1. ]] U [[3. 8. 1. ] [0. 4. 1. ] [0. 0. 0.8]] . QR . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . Q, R = LA.qr(A) print(&#39;Q&#39;, Q, &#39;&#39;, &#39;R&#39;, R, sep=&#39; n&#39;) . Q [[-0.3 0.1 0.9] [-0.9 -0. -0.3] [-0. -1. 0.2]] R [[-3.2 -8.2 -1.3] [ 0. -4. -0.9] [ 0. 0. 0.8]] . Diagonalization (Eigendecomposition) . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . la, S = npLA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . print(np.diagflat(la)) . [[9.4+0.j 0. +0.j 0. +0.j] [0. +0.j 0.3+1.j 0. +0.j] [0. +0.j 0. +0.j 0.3-1.j]] . print(S @ np.diagflat(la) @ inv(S)) . [[1.-0.j 2.+0.j 1.+0.j] [3.-0.j 8.-0.j 1.+0.j] [0.-0.j 4.-0.j 1.+0.j]] . &amp;#x21e7; . Subspaces . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . Column Space C(A) . (Using SVD, Orthonormal basis) . col_sp_A_orthonormal_basis_by_SVD = LA.orth(A) print(col_sp_A_orthonormal_basis_by_SVD) . [[-0.2 0.1 1. ] [-0.9 0.4 -0.3] [-0.4 -0.9 -0. ]] . Manually . QR . Orthonormal basis . Q, R, P = LA.qr(A, pivoting=True) rank_A = npLA.matrix_rank(A) print(&#39;Q&#39;, Q, &#39;&#39;, &#39;R&#39;, R, &#39;&#39;, &#39;P&#39;, P, &#39;&#39;, &#39;rank&#39;, rank_A, sep=&#39; n&#39;) . Q [[-0.2 -0.3 -0.9] [-0.9 -0.4 0.3] [-0.4 0.9 -0.2]] R [[-9.2 -2.8 -1.5] [ 0. -1.4 0.2] [ 0. 0. -0.8]] P [1 0 2] rank 3 . col_sp_A_orthonormal_basis_by_QR = Q[:, :rank_A] print(col_sp_A_orthonormal_basis_by_QR) . [[-0.2 -0.3 -0.9] [-0.9 -0.4 0.3] [-0.4 0.9 -0.2]] . Independent columns . Q, R = LA.qr(A) print(&#39;Q&#39;, Q, &#39;&#39;, &#39;R&#39;, R, &#39;&#39;, &#39;rank&#39;, rank_A, sep=&#39; n&#39;) . Q [[-0.3 0.1 0.9] [-0.9 -0. -0.3] [-0. -1. 0.2]] R [[-3.2 -8.2 -1.3] [ 0. -4. -0.9] [ 0. 0. 0.8]] rank 3 . def obtain_unique_indices_of_first_nonzero_col_in_each_row(U_resulted_by_decomposition: np.ndarray) -&gt; list: # I should first convert all the &quot;-0.&quot; to &quot;0.&quot; so that nonzero() can find them. U_copy = U_resulted_by_decomposition.copy() U_copy[abs(U_copy) &lt; 1.e-7] = 0 # Because some rows in U may not have even one nonzero element, # I have to find the index for the first one in two steps. index_of_all_nonzero_cols_in_each_row = ( [U_copy[i, :].nonzero()[0] for i in range(U_copy.shape[0])] ) index_of_first_nonzero_col_in_each_row = ( [indices[0] for indices in index_of_all_nonzero_cols_in_each_row if len(indices) &gt; 0] ) # Because two rows or more may have the same indices for their first nonzero element, # I should remove duplicates. unique_indices = sorted(list(set(index_of_first_nonzero_col_in_each_row))) return unique_indices . index_of_linearly_independent_cols_of_A = obtain_unique_indices_of_first_nonzero_col_in_each_row(R) col_sp_A_independent_columns_by_QR = A[:, index_of_linearly_independent_cols_of_A] print(col_sp_A_independent_columns_by_QR) . [[1 2 1] [3 8 1] [0 4 1]] . We can create them by Q and R too: . col_sp_A_independent_columns_by_QR = Q @ R[:, index_of_linearly_independent_cols_of_A] print(col_sp_A_independent_columns_by_QR) . [[1. 2. 1.] [3. 8. 1.] [0. 4. 1.]] . LU (Independent columns) . P, L, U = LA.lu(A) print(&#39;P&#39;, P, &#39;&#39;, &#39;L&#39;, L, &#39;&#39;, &#39;U&#39;, U, sep=&#39; n&#39;) . P [[0. 0. 1.] [1. 0. 0.] [0. 1. 0.]] L [[ 1. 0. 0. ] [ 0. 1. 0. ] [ 0.3 -0.2 1. ]] U [[3. 8. 1. ] [0. 4. 1. ] [0. 0. 0.8]] . index_of_linearly_independent_cols_of_A = obtain_unique_indices_of_first_nonzero_col_in_each_row(U) col_sp_A_independent_columns_by_LU = A[:, index_of_linearly_independent_cols_of_A] print(col_sp_A_independent_columns_by_LU) . [[1 2 1] [3 8 1] [0 4 1]] . We can create them by P, L, and U too: . col_sp_A_independent_columns_by_LU = P @ L @ U[:, index_of_linearly_independent_cols_of_A] print(col_sp_A_independent_columns_by_LU) . [[1. 2. 1.] [3. 8. 1.] [0. 4. 1.]] . Null Space N(A) . (Using SVD, Orthonormal basis) . null_sp_A = LA.null_space(A) print(null_sp_A) . [] . LA.norm(null_sp_A) . 0.0 . Row Space C(At) . row_sp_A = LA.orth(A.T) print(row_sp_A) . [[-0.3 0.9 0.3] [-0.9 -0.2 -0.2] [-0.2 -0.3 0.9]] . Left Null Space N(At) . left_null_sp_A = LA.null_space(A.T) print(left_null_sp_A) . [] . &amp;#x21e7; . Rank-one matrix . u = np.array([[1], [2], [3]]) v = np.array([[1], [4], [5]]) A = u @ v.T print(A) . [[ 1 4 5] [ 2 8 10] [ 3 12 15]] . npLA.matrix_rank(A) . 1 . Why is computing determinant and eigenvalues for rank-one matrices easy? . All eigenvalues of a rank-one matrix are zeros except one of them, which happens when u is not orthogonal to v (i.e. when A is diagonalizable) and is given by a simple dot product: . print(u.T @ v) . [[24]] . print(LA.eigvals(A)) . [24.+0.j -0.+0.j 0.+0.j] . Because rank-one matrices are singular, their determinant is simply zero. . LA.det(A) . 0.0 . If I write a matrix as a sum of only rank-one matrices, how can it help with computing eigenvalues for the original matrix? . See the good answers for this question on math.stackexchange.com: Eigenvalues of a sum of rank-one matrices? . &amp;#x21e7; . Least Squares . A = np.column_stack([np.ones(3), np.arange(1, 4)]).astype(&#39;int&#39;) b = np.array([1, 2, 2]) print(&#39;A&#39;, A, &#39;&#39;, &#39;b&#39;, b, sep=&#39; n&#39;) . A [[1 1] [1 2] [1 3]] b [1 2 2] . x_hat, *_ = LA.lstsq(A, b) print(x_hat) . [0.7 0.5] . The power of lstsq() is that it does not need N(A) == 0. . Manually . In this manual approach, all columns of A should be linearly independent. . At_A = A.T @ A At_b = A.T @ b print(&#39;At_A&#39;, At_A, &#39;&#39;, &#39;At_b&#39;, At_b, sep=&#39; n&#39;) . At_A [[ 3 6] [ 6 14]] At_b [ 5 11] . x_hat = inv(At_A) @ At_b print(x_hat) . [0.7 0.5] . Or: . x_hat = LA.solve(At_A, At_b) print(x_hat) . [0.7 0.5] . Fitting a line/parabola . pt_x = np.array([1. , 2.5, 3.5, 4. , 5. , 7. , 8.5]) pt_y = np.array([0.3, 1.1, 1.5, 2.0, 3.2, 6.6, 8.6]) line_A = np.column_stack([pt_x, np.ones(len(pt_x))]) line_x_hat, line_residues, *_ = LA.lstsq(line_A, pt_y) line_a, line_b = line_x_hat parabola_A = np.column_stack([pt_x ** 2, pt_x, np.ones(len(pt_x))]) parabola_x_hat, parabola_residues, *_ = LA.lstsq(parabola_A, pt_y) parabola_a, parabola_b, parabola_c = parabola_x_hat print(&#39;Residues&#39;) print(&#39;line: t&#39;, line_residues, sep=&#39; t&#39;) print(&#39;parabola:&#39;, parabola_residues, sep=&#39; t&#39;) . Residues line: 3.1152232142857175 parabola: 0.3954624919193907 . plt.plot(pt_x, pt_y, &#39;o&#39;, label=&#39;Original data&#39;) input_x = np.arange(0, 9, .1) plt.plot(input_x, line_a * input_x + line_b, label=&#39;Fitted line&#39;) plt.plot(input_x, parabola_a * input_x ** 2 + parabola_b * input_x + parabola_c, label=&#39;Fitted parabola&#39;) plt.grid(alpha=0.25) plt.legend() . &lt;matplotlib.legend.Legend at 0x1174049d0&gt; . &amp;#x21e7; . Properties of the determinant . A, B = [np.random.rand(3, 3) for _ in range(2)] . $|AB| = |A||B|$ . assert_allclose( det(A @ B), det(A) * det(B) ) . $|A^{-1}| = frac{1}{|A|}$ . assert_allclose( det(inv(A)), 1 / det(A) ) . $|A^2|=|A|^2$ . assert_allclose( det(matrix_power(A, 2)), det(A) ** 2 ) . $|2A|=2^n |A|$ . assert_allclose( det(2 * A), 2 ** A.shape[0] * det(A) ) . $|A^T|=|A|$ . assert_allclose( det(A.T), det(A) ) . $|U|=|A|$ . *_, U = LA.lu(A) assert_allclose( abs(det(U)), abs(det(A)), ) . $|Q|=1$ . Q_a_unitary_matrix = LA.orth(A) assert_allclose( abs(det(Q_a_unitary_matrix)), 1, atol=0.1 ) . &amp;#x21e7; . Eigenvalues and eigenvectors . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . la, S = npLA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . Product of eigenvalues . from functools import reduce from operator import mul product_of_eigenvalues = reduce(mul, la) assert_allclose( product_of_eigenvalues, det(A) ) . Sum of eigenvalues . A.trace() . 10 . sum_of_eigenvalues = la.sum() assert_allclose( sum_of_eigenvalues, A.trace() ) . Adding to the diagonal adds to lambdas . assert_allclose( LA.eigvals(A + 100 * np.identity(3)), la + 100 ) . Attributes of a diagonal matrix . D = np.diagflat(np.arange(1, 4)) print(D) . [[1 0 0] [0 2 0] [0 0 3]] . la, S = LA.eig(D) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [1.+0.j 2.+0.j 3.+0.j] S [[1. 0. 0.] [0. 1. 0.] [0. 0. 1.]] . def test_in_a_diagonal_matrix_eigenvalues_are_the_ones_on_the_diagonal(): assert_allclose( np.diag(D), la ) test_in_a_diagonal_matrix_eigenvalues_are_the_ones_on_the_diagonal() . def test_in_a_diagonal_matrix_eigenvectors_form_the_identity(): assert_allclose( S, np.identity(D.shape[0]) ) test_in_a_diagonal_matrix_eigenvectors_form_the_identity() . Rotation matrix often has complex lambdas . from numpy import sin, cos def generate_2_by_2_rotation_matrix(theta): return np.array([[cos(theta), -sin(theta)], [sin(theta), cos(theta)]]) R_90 = generate_2_by_2_rotation_matrix(np.pi / 2) print(R_90) . [[ 0. -1.] [ 1. 0.]] . def test_R_90_is_antisymmetric(): assert_allclose( -R_90.T, R_90, atol=1e-7 ) test_R_90_is_antisymmetric() . la = LA.eigvals(R_90) print(la) . [0.+1.j 0.-1.j] . def test_R_90_has_pure_imaginary_lambdas(): assert_allclose( la.real, np.zeros_like(la.real), atol=1e-7 ) test_R_90_has_pure_imaginary_lambdas() . &amp;#x21e7; . Diagonalizability . Algebraic &amp; Geometric Multiplicity . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . I&#39;ve used the eig() by numpy.linalg because it doesn&#39;t show zero imaginary parts. . la, S = npLA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . from collections import Counter def compute_algebraic_multiplicities(M: np.ndarray) -&gt; dict: return Counter(npLA.eigvals(M)) def compute_geometric_multiplicities(M: np.ndarray) -&gt; dict: geo_multiplicities = {} for l in npLA.eigvals(M): A_minus_lambda_I = M - l * np.identity(M.shape[0]) eigenspace = LA.null_space(A_minus_lambda_I) dim_of_eigenspace = eigenspace.shape[1] geo_multiplicities[l] = dim_of_eigenspace return geo_multiplicities def print_alg_and_geo_multiplicities(M: np.ndarray): alg_ms = compute_algebraic_multiplicities(M) geo_ms = compute_geometric_multiplicities(M) print(&#39;lambda &#39;, &#39;A.M&#39;, &#39;G.M&#39;, sep=&#39; &#39;) for l in sorted(alg_ms, reverse=True): print(f&#39;{l:#8.1f}&#39;, f&#39;{alg_ms[l]:#3d}&#39;, f&#39;{geo_ms[l]:#3d}&#39;, sep=&#39; &#39;) print_alg_and_geo_multiplicities(A) . lambda A.M G.M 9.4+0.0j 1 1 0.3+1.0j 1 1 0.3-1.0j 1 1 . Defective matrix . Any nontrivial Jordan block of 2×2 or larger (that is, not completely diagonal) is defective (degenerate). . J = np.array([[3, 1], [0, 3]]) print(J) . [[3 1] [0 3]] . la, S = LA.eig(J) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [3.+0.j 3.+0.j] S [[ 1. -1.] [ 0. 0.]] . assert_allclose( npLA.matrix_rank(S), 1, atol=0.1 ) . This Jordan matrix has only one eigenvector. . Diagonalizable matrix . $A=S Lambda S^{-1}$ . Normal . The square matrix A is normal $ Longleftrightarrow$ $AA^H = A^HA$. . A normal matrix is never defective. (It is always diagonalizable.) . Matrices are diagonalizable by unitary matrices ($A=Q Lambda Q^H$) if and only if they are normal. . Hermitian . A Hermitian matrix is always normal, so it is always diagonalizable by unitary matrices. . Unitary . A Unitary matrix is always normal. . &amp;#x21e7; . Matrix Power $A^{k}$ . A diagonal matrix . D = np.diagflat(np.arange(1, 4)) print(D) . [[1 0 0] [0 2 0] [0 0 3]] . k = 2 print(matrix_power(D, k)) . [[1 0 0] [0 4 0] [0 0 9]] . assert_allclose( matrix_power(D, k), D ** k ) . Any matrix . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . If A is diagonalizable, $A^k=SΛ^kS^{-1}$. . la, S = LA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . k = 2 assert_allclose( matrix_power(A, k), S @ np.diagflat(la) ** k @ inv(S) ) . &amp;#x21e7; . Matrix Exponential $e^{At}$ . A diagonal matrix . D = np.diagflat(np.arange(1, 4)) print(D) . [[1 0 0] [0 2 0] [0 0 3]] . print(expm(D)) . [[ 2.7 0. 0. ] [ 0. 7.4 0. ] [ 0. 0. 20.1]] . t = 2 assert_allclose( expm(D * t), np.diagflat(np.e ** (np.diag(D) * t)) ) . Any matrix . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . If A is diagonalizable, $e^{At}=Se^{Λt}S^{-1}$. . la, S = LA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . t = 2 assert_allclose( expm(A * t), S @ expm(np.diagflat(la) * t) @ inv(S) ) . &amp;#x21e7; . Systems of difference equations . Discrete $u_{k}=A^{k}u_{0}$ . e.g. Fibonacci . $f_{0}$ $f_{1}$ $f_{2}$ $f_{3}$ $f_{4}$ $f_{5}$ $f_{6}$ $f_{7}$ $...$ $f_{100}$ . 0 | 1 | 1 | 2 | 3 | 5 | 8 | 13 | $...$ | ? | . $f_{k+2} = f_{k+1} + f_{k} rightarrow $ 2nd order differential equation (with 2nd derivative) . &quot;I want to get a two by two system first order, instead of a scalar system second order.&quot; . 1st order system $ rightarrow begin{cases} f_{k+1} + f_{k} = f_{k+2} f_{k+1} + 0 = f_{k+1} end{cases} rightarrow begin{bmatrix} 1 &amp; 1 1 &amp; 0 end{bmatrix} begin{bmatrix} f{k+1} f{k} . end{bmatrix} . begin{bmatrix} f_{k+2} f_{k+1} end{bmatrix} rightarrow begin{bmatrix} 1 &amp; 1 1 &amp; 0 end{bmatrix} u{k} = u{k+1} $ . $ Rightarrow u{k+1} = A u{k} , u{0} = begin{bmatrix} f{1} f_{0} . end{bmatrix} . begin{bmatrix} 1 0 end{bmatrix}$ . $ Rightarrow u_{k} = A^{k} u_{0} = S Lambda^{k} c , c = S^{-1} u_{0} $ . A = np.array([[1, 1], [1, 0]]) u_0 = np.array([1, 0], dtype=&#39;float&#39;) def u_by_recursion(k_): global A, u_0 if k_ == 0: return u_0 else: return A @ u_by_recursion(k_ - 1) def u_by_diagonalization(k_): global A, u_0 la_, S_ = npLA.eig(A) if k_ == 0: return u_0 else: return S_ @ np.diagflat(la_ ** k_) @ inv(S_) @ u_0 . def assert_diff_fib_are_close(): n = 100 assert_allclose( u_by_recursion(n), u_by_diagonalization(n) ) assert_diff_fib_are_close() . [round(u_by_diagonalization(n)[1]) for n in range(8)] . [0, 1, 1, 2, 3, 5, 8, 13] . print(f&#39;{round(u_by_diagonalization(100)[1]):_}&#39;) . 354_224_848_179_263_045_632 . Convergence . Stability . $ forall i: | lambda_{i}|&lt;1$ . def matrix_power_leads_to_stability(la_): return (np.absolute(la_) &lt; .9).all() tolerance_factor = 1_000_000 def assert_norm_of_last_vector_is_by_far_smaller_than_first_one(v_0, v_last): assert_array_less( tolerance_factor * LA.norm(v_last), LA.norm(v_0) ) . Steady State . $ exists i: | lambda_{i}|=1, forall j: | lambda_{j}| leq 1$ . def matrix_power_leads_to_steady_state(la_): return (np.absolute(la_) &gt; .9).any() and (np.absolute(la_) &lt;= 1.1).all() def assert_norm_of_last_vector_is_not_far_away_than_first_one(v_0, v_last): # It doesn&#39;t blow up. assert_array_less( LA.norm(v_last), tolerance_factor * LA.norm(v_0) ) # It doesn&#39;t lead to stability. assert_array_less( LA.norm(v_0), tolerance_factor * LA.norm(v_last) ) . Blow Up . $ exists i : | lambda_{i}|&gt;1$ . def matrix_power_blows_up(la_): return (np.absolute(la_) &gt; 1.1).any() def assert_norm_of_last_vector_is_by_far_bigger_than_first_one(v_0, v_last): try: assert_(np.isinf(v_last).any()) except AssertionError: assert_array_less( tolerance_factor * LA.norm(v_0), LA.norm(v_last) ) . Analyze . A = create_my_array() u_0 = np.ones(A.shape[0]) print(&#39;A&#39;, A, &#39;&#39;, &#39;u_0&#39;, u_0[:, np.newaxis], sep=&#39; n&#39;) . A [[1 2 1] [3 8 1] [0 4 1]] u_0 [[1.] [1.] [1.]] . la = npLA.eigvals(A) print(&#39;la&#39;, la, &#39;&#39;, sep=&#39; n&#39;) print(&#39;la_abs&#39;, np.absolute(la), sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] la_abs [9.4 1. 1. ] . k = 100 A_to_the_k = matrix_power(A, k) u_k = A_to_the_k @ u_0 convergence_message = { &#39;stability&#39;: f&#39;{Styles.GREEN}It is stable!{Styles.END}&#39;, &#39;steady_state&#39;: f&#39;{Styles.YELLOW}It approaches a steady state!{Styles.END}&#39;, &#39;blow_up&#39;: f&#39;{Styles.RED}It blows up!{Styles.END}&#39; } convergence_result = &#39;&#39; if matrix_power_leads_to_stability(la): assert_norm_of_last_vector_is_by_far_smaller_than_first_one(u_0, u_k) convergence_result = &#39;stability&#39; if matrix_power_leads_to_steady_state(la): assert_norm_of_last_vector_is_not_far_away_than_first_one(u_0, u_k) convergence_result = &#39;steady_state&#39; if matrix_power_blows_up(la): assert_norm_of_last_vector_is_by_far_bigger_than_first_one(u_0, u_k) convergence_result = &#39;blow_up&#39; print(convergence_message[convergence_result]) # print(&#39;&#39;, &#39;A_to_the_k&#39;, A_to_the_k, sep=&#39; n&#39;) print(&#39;&#39;, &#39;u_k&#39;, u_k[:, np.newaxis], sep=&#39; n&#39;) . It blows up! u_k [[ 1.7e+18] [-1.3e+19] [-3.4e+18]] . Graph . def draw_2d_convergence_graph(x_, y_, color): fig, ax = plt.subplots(figsize=(7, 7)) ax.plot(x_, y_, &#39;o-&#39;, lw=0.5, color=color) # Compute max_lim based on plotted data x_lim = abs(max(ax.get_xlim(), key=abs)) y_lim = abs(max(ax.get_ylim(), key=abs)) max_lim = max(x_lim, y_lim) # Position xyz axes to the center ax.set_xlim(xmin=-max_lim, xmax=max_lim) ax.set_ylim(ymin=-max_lim, ymax=max_lim) ax.grid(True, lw=.5) def draw_3d_convergence_graph(x_, y_, z_, color): ax = plt.figure(figsize=(7, 7)).add_subplot(projection=&#39;3d&#39;) ax.plot(x_, y_, z_, &#39;.-&#39;, lw=0.5, color=color) draw_xyz_axes_at_center(ax) ax.set_xlabel(&#39;x axis&#39;) ax.set_ylabel(&#39;y axis&#39;) ax.set_zlabel(&#39;z axis&#39;) plt.show() def draw_convergence_graph(u_, color): if u_.shape[0] == 2: draw_2d_convergence_graph(u_[0, :], u_[1, :], color) elif u_.shape[0] == 3: draw_3d_convergence_graph(u_[0, :], u_[1, :], u_[2, :], color) graph_color = { &#39;stability&#39;: &#39;green&#39;, &#39;steady_state&#39;: &#39;yellow&#39;, &#39;blow_up&#39;: &#39;red&#39; } u = [u_0] for i in range(k): u.append(A @ u[-1]) # %matplotlib notebook u = np.array(u).T draw_convergence_graph(u, graph_color[convergence_result]) . Continuous $u(t)=e^{At}u(0)$ . e.g. A 2&#215;2 system of diff eqs . $ begin{cases} frac{du_{1}}{dt} = -u_{1}+2u_{2} , u_{1}(0)=1 , u_{1}(t)=? frac{du_{2}}{dt} = u_{1}-2u_{2} , u_{2}(0)=0 , u_{2}(t)=? end{cases} A = begin{bmatrix} -1 &amp; 2 1 &amp; -2 end{bmatrix} , u= begin{bmatrix} u_{1} u_{2} end{bmatrix} rightarrow frac{du}{dt} = Au , u(0)= begin{bmatrix} 1 0 end{bmatrix} u(t)=e^{At}u(0)=Se^{ Lambda t} c , c = S^{-1} u(0) $ . A = np.array([[-1, 2], [ 1, -2]]) u_0 = np.array([1, 0], dtype=&#39;float&#39;) def u(t_): return expm(A * t_) @ u_0 . $ u_{1}(100)=? u_{2}(100)=? $ . print(u(100).reshape(2, 1)) . [[0.7] [0.3]] . e.g. A 2nd order diff eq . $ y^{&#39;&#39;}+by^{&#39;}+ky=0 Rightarrow begin{cases} y^{&#39;&#39;}=-by^{&#39;}-ky y^{&#39;}= y^{&#39;}+0 end{cases} Rightarrow begin{bmatrix} y^{&#39;&#39;} y^{&#39;} . end{bmatrix} . begin{bmatrix} -b &amp; -k 1 &amp; 0 end{bmatrix} begin{bmatrix} y^{&#39;} y end{bmatrix} Rightarrow frac{du}{dt}=u^{&#39;}=Au Rightarrow u(t)=e^{At}u(0) $ . Convergence . Stability . $ forall i: Re lambda_{i}&lt;0$ . def matrix_exponential_leads_to_stability(la_): return (la_.real &lt;= -0.1).all() . Steady State . $ exists i: Re lambda_{i}=0, forall j: Re lambda_{j} leq 0$ . def matrix_exponential_leads_to_steady_state(la_): return (la_.real &lt; 0.1).all() and (-0.1 &lt; la_.real).any() . Blow Up . $ exists i: Re lambda_{i}&gt;0$ . def matrix_exponential_blows_up(la_): return (la_.real &gt;= 0.1).any() . Analyze . A = create_my_array() u_0 = np.ones(A.shape[0]) print(&#39;A&#39;, A, &#39;&#39;, &#39;u_0&#39;, u_0[:, np.newaxis], sep=&#39; n&#39;) . A [[1 2 1] [3 8 1] [0 4 1]] u_0 [[1.] [1.] [1.]] . la = npLA.eigvals(A) print(&#39;la&#39;, la, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] . t = 100 e_to_the_At = expm(A * t) u_t = e_to_the_At @ u_0 convergence_result = &#39;&#39; if matrix_exponential_leads_to_stability(la): assert_norm_of_last_vector_is_by_far_smaller_than_first_one(u_0, u_t) convergence_result = &#39;stability&#39; if matrix_exponential_leads_to_steady_state(la): assert_norm_of_last_vector_is_not_far_away_than_first_one(u_0, u_t) convergence_result = &#39;steady_state&#39; if matrix_exponential_blows_up(la): assert_norm_of_last_vector_is_by_far_bigger_than_first_one(u_0, u_t) convergence_result = &#39;blow_up&#39; print(convergence_message[convergence_result]) # print(&#39;&#39;, &#39;e_to_the_At&#39;, e_to_the_At, sep=&#39; n&#39;) print(&#39;&#39;, &#39;u_t&#39;, u_t[:, np.newaxis], sep=&#39; n&#39;) . It blows up! u_t [[inf] [inf] [inf]] . Graph . u = [u_0] dt = .1 for i in range(int(t / dt)): du = A @ u[-1] * dt u.append(u[-1] + du) u = np.array(u).T draw_convergence_graph(u, graph_color[convergence_result]) . &amp;#x21e7; . Markov matrix . A = create_a_Markov_matrix() print(A) . [[0.1 0. 0.3] [0.2 1. 0.3] [0.7 0. 0.4]] . la, S = npLA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [-0.2 0.7 1. ] S [[ 0.7 -0.3 -0. ] [ 0.1 0.8 -1. ] [-0.7 -0.5 -0. ]] . All entries are 0 or positive . def assert_all_entries_are_0_or_positive(M): assert_( (M &gt;= 0).all() ) assert_all_entries_are_0_or_positive(A) . All columns add to 1 . def assert_all_columns_add_to_1(M): assert_allclose( np.sum(M, axis=0).all(), 1 ) assert_all_columns_add_to_1(A) . $ exists i: lambda_{i} = 1$ . def assert_at_least_an_eigenvalue_is_close_to_1(la_): assert_( np.isclose(la_, 1).any() ) assert_at_least_an_eigenvalue_is_close_to_1(la) . $ forall j ne i , | lambda_{j}| leq 1$ . def assert_all_eigenvalues_are_less_than_or_close_to_1(la_): assert_array_less( np.absolute(la_), np.full_like(la_, 1.1), ) assert_all_eigenvalues_are_less_than_or_close_to_1(la) . It converges to a positive steady state . k = 100 A_to_the_k = matrix_power(A, k) u_0 = np.ones(A.shape[0]) u_k = A_to_the_k @ u_0 la = npLA.eigvals(A_to_the_k) assert_array_less(np.zeros_like(u_k), u_k) assert_norm_of_last_vector_is_not_far_away_than_first_one(u_0, u_k) . $A^{k}$ is still Markov . assert_all_entries_are_0_or_positive(A_to_the_k) assert_all_columns_add_to_1(A_to_the_k) assert_at_least_an_eigenvalue_is_close_to_1(la) assert_all_eigenvalues_are_less_than_or_close_to_1(la) . &amp;#x21e7; . Expansion with a basis . v = np.array([1, 2, 3]) print(&#39;Vector&#39;, v, sep=&#39; n&#39;) . Vector [1 2 3] . With A . A = create_a_square_invertible_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . x = inv(A.T @ A) @ A.T @ v print(x) . [-1. 0.5 1. ] . assert_allclose( A @ x, v ) . With Q (orthonormal basis) . Q = LA.orth(A) print(Q) . [[-0.2 0.1 1. ] [-0.9 0.4 -0.3] [-0.4 -0.9 -0. ]] . x = Q.T @ v print(&#39;Cofactors on Q&#39;, x, sep=&#39; n&#39;) . Cofactors on Q [-3.2 -1.9 0.4] . assert_allclose( Q @ x, v ) . With S (eigenvectors) . la, S = npLA.eig(A) print(&#39;la&#39;, la, &#39;&#39;, &#39;S&#39;, S, sep=&#39; n&#39;) . la [9.4+0.j 0.3+1.j 0.3-1.j] S [[ 0.3+0.j 0. -0.5j 0. +0.5j] [ 0.9+0.j -0.1+0.2j -0.1-0.2j] [ 0.4+0.j 0.8+0.j 0.8-0.j ]] . x = inv(S.T @ S) @ S.T @ v print(x) . [2.8-0.j 1.2+0.2j 1.2-0.2j] . assert_allclose( S @ (x * la), A @ v ) . &amp;#x21e7; . Complex Vectors and Matrices . z = np.array([1, 1j]) print(z) . [1.+0.j 0.+1.j] . length_squared = z.conj().T @ z assert_allclose( length_squared, LA.norm(z) ** 2 ) . Hermitian matrix . A = create_a_Hermitian_array() print(A) . [[ 1.+0.j 0.+2.j 1.+1.j] [-0.-2.j 8.+0.j 4.-3.j] [ 1.-1.j 4.+3.j -3.+0.j]] . assert_allclose( A.conj().T, A ) . Unitary matrix . Q = create_a_unitary_array() print(Q) . [[0.5+0.5j 0.5-0.5j] [0.5-0.5j 0.5+0.5j]] . assert_allclose( inv(Q), Q.conj().T ) . &amp;#x21e7; . Positive Definite Matrices . A = create_my_array() print(A) . [[1 2 1] [3 8 1] [0 4 1]] . la = LA.eigvals(A) (la &gt; 0).all() . True . U = LA.lu(A)[2] pivots = np.diag(U) (pivots &gt; 0).all() . True . sub_dets_of_A = np.array([det(A[:i, :i]) for i in range(1, A.shape[0] + 1)]) (sub_dets_of_A &gt; 0).all() . True .",
            "url": "https://shahrokh-bahtooei.github.io/blog/2022/06/10/LinearAlgebra_GilbertStrang.html",
            "relUrl": "/2022/06/10/LinearAlgebra_GilbertStrang.html",
            "date": " • Jun 10, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://shahrokh-bahtooei.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://shahrokh-bahtooei.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://shahrokh-bahtooei.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shahrokh-bahtooei.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}